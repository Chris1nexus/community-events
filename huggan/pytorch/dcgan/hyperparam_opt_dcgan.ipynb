{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install datasets\n",
    "!pip install ipywidgets\n",
    "!pip install pandas\n",
    "!git clone https://github.com/Chris1nexus/community-events.git\n",
    "%cd community-events\n",
    "!pip install .\n",
    "%cd ..\n",
    "!rm -rf community-events\n",
    "!pip install wandb\n",
    "#!huggingface-cli login\n",
    "#!wandb login\n",
    "#!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7abdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from subprocess import call\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hyperparams_dcgan = {\n",
    "    \n",
    "    'lr':[0.00005], \n",
    "    'latent_dim':[100],\n",
    "        'generator_hidden_size':[64],\n",
    "    'discriminator_hidden_size':[64],\n",
    "    \n",
    "    \n",
    "        'image_size':[64], \n",
    "        'num_channels':[3], \n",
    "    'dataset':['Chris1/cryptopunks_HQ'],  \n",
    "'num_workers':[8], \n",
    "     'batch_size':[128],\n",
    "    \n",
    "    'num_epochs':[2000],  \n",
    "        'beta1':[0.5], \n",
    " #'fp16':[False],\n",
    "    'mixed_precision':['no'], \n",
    "    'output_dir':['./output'],\n",
    "    #'cpu':[False], \n",
    "    'wandb':[True],\n",
    "    'logging_steps':[5],\n",
    "    'push_to_hub':[True], \n",
    "    'model_name':['test_dcgan_punks_HQ_7'],\n",
    "     'organization_name':['Chris1'], \n",
    "    \n",
    "    \n",
    "                     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15d80b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, beta1=0.5, cpu=False, dataset='Chris1/cryptopunks_HQ', discriminator_hidden_size=64, fp16=False, generator_hidden_size=64, image_size=64, latent_dim=100, logging_steps=5, lr=5e-05, mixed_precision='no', model_name='test_dcgan_punks_HQ_7_1', num_channels=3, num_epochs=2000, num_workers=8, organization_name='Chris1', output_dir=PosixPath('log_all7_local_dcgan_punks_HQ/1'), push_to_hub=True, wandb=True)\n",
      "Namespace(batch_size=128, beta1=0.5, cpu=False, dataset='Chris1/cryptopunks_HQ', discriminator_hidden_size=64, fp16=False, generator_hidden_size=64, image_size=64, latent_dim=100, logging_steps=5, lr=5e-05, mixed_precision='no', model_name='test_dcgan_punks_HQ_7_1', num_channels=3, num_epochs=2000, num_workers=8, organization_name='Chris1', output_dir=PosixPath('log_all7_local_dcgan_punks_HQ/1'), push_to_hub=True, wandb=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: chris1nexus (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.14 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.12.12\n",
      "wandb: Run data is saved locally in /home/xrh1/experiments/huggan/huggan_repo/community-events/huggan/pytorch/dcgan/wandb/run-20220410_234518-33f8fwcf\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run balmy-donkey-1\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/chris1nexus/log_all7_local_dcgan_punks_HQ--1\n",
      "wandb: üöÄ View run at https://wandb.ai/chris1nexus/log_all7_local_dcgan_punks_HQ--1/runs/33f8fwcf\n",
      "WARNING:datasets.builder:Using custom data configuration Chris1--cryptopunks_HQ-cf2ec687559f7bbd\n",
      "WARNING:datasets.builder:Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/Chris1--cryptopunks_HQ-cf2ec687559f7bbd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 980.66it/s]\n",
      "WARNING:datasets.builder:Using custom data configuration Chris1--cryptopunks_HQ-cf2ec687559f7bbd\n",
      "WARNING:datasets.builder:Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/Chris1--cryptopunks_HQ-cf2ec687559f7bbd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100% 1/1 [00:00<00:00, 858.08it/s]\n",
      "INFO:__main__:***** Running training *****\n",
      "INFO:__main__:  Num Epochs = 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1999/2000] [Batch 39/40] [D loss: 100.000000] [G loss: 0.000000] ETA: 0:00:00.35184004300593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 370, in <module>\r\n",
      "    main()\r\n",
      "  File \"train.py\", line 366, in main\r\n",
      "    training_function({}, args)\r\n",
      "  File \"train.py\", line 356, in training_function\r\n",
      "    generator.module.push_to_hub(\r\n",
      "  File \"/home/xrh1/experiments/huggan/hugenv/lib/python3.8/site-packages/huggan/pytorch/huggan_mixin.py\", line 97, in push_to_hub\r\n",
      "    if repo_url is None and not os.path.exists(repo_path_or_name):\r\n",
      "NameError: name 'os' is not defined\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb:                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Killing subprocess 3096627\n",
      "Killing subprocess 3096628\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "EXPERIMENTS_DATA_CSV = 'experiments.csv'\n",
    "\n",
    "if not os.path.exists(EXPERIMENTS_DATA_CSV):\n",
    "    experiments_df = pd.DataFrame()\n",
    "else:\n",
    "    experiments_df = pd.read_csv(EXPERIMENTS_DATA_CSV)\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = 'log_all7_local_dcgan_punks_HQ'\n",
    "    \n",
    "\n",
    "\n",
    "for idx, grid in enumerate(ParameterGrid(hyperparams_dcgan)):\n",
    "\n",
    "        copy_grid = copy.deepcopy(grid)\n",
    "        if 'dataset_name' in copy_grid:\n",
    "            del copy_grid['dataset_name']\n",
    "        if 'dataset' in copy_grid:\n",
    "            del copy_grid['dataset']\n",
    "        if 'output_dir' in copy_grid:\n",
    "            del copy_grid['output_dir']\n",
    "            \n",
    "        experiment_name =  '--'.join([f'{k}__{v}'  for k,v in copy_grid.items() ])\n",
    "        call_params = ['accelerate', 'launch',\n",
    "                       '--config_file','~/.cache/huggingface/accelerate/default_config.yaml',\n",
    "                       'train.py']\n",
    "        \n",
    "        \n",
    "        experiment_id = len(experiments_df)\n",
    "        grid['output_dir'] = experiment_name\n",
    "        \n",
    "        experiments_df = experiments_df.append(grid,ignore_index=True)\n",
    "        grid['output_dir'] = f'experiments/{EXPERIMENT_NAME}/{experiment_id}'\n",
    "        grid['model_name'] = f'{grid[\"model_name\"]}_{experiment_id}'\n",
    "        for k,v in grid.items():\n",
    "            \n",
    "             \n",
    "            call_params.append(f'--{k}' )\n",
    "            if k not in  ['cpu', 'wandb','fp16','push_to_hub']:\n",
    "                call_params.append(f'{v}' )\n",
    "        call(call_params)\n",
    "        \n",
    "        \n",
    "        experiments_df.to_csv(EXPERIMENTS_DATA_CSV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
