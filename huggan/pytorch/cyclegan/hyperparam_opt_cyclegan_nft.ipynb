{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install datasets\n",
    "!pip install ipywidgets\n",
    "!pip install pandas\n",
    "!git clone https://github.com/Chris1nexus/community-events.git\n",
    "%cd community-events\n",
    "!pip install .\n",
    "%cd ..\n",
    "!rm -rf community-events\n",
    "!pip install wandb\n",
    "#!huggingface-cli login\n",
    "#!wandb login\n",
    "#!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from subprocess import call\n",
    "import os\n",
    "import json\n",
    "from huggingface_hub.hf_api import HfApi\n",
    "\n",
    "hfapi = HfApi()\n",
    "huggingnft_models = [model.modelId.split('/')[-1] for model in hfapi.list_models(author=\"huggingnft\") if '__2__' in model.modelId.split('/')[-1] ]\n",
    "\n",
    "\n",
    "chris1_models = [model.modelId.split('/')[-1] for model in hfapi.list_models(author=\"Chris1\") if '__2__' in model.modelId.split('/')[-1] ]\n",
    "created_models = set(huggingnft_models + chris1_models )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99d35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 356/541] [D loss: 0.228799] [G loss: 3.415998, adv: 0.900602, cycle: 0.176970, identity: 0.149139] ETA: 15:28:53.780552744706"
     ]
    }
   ],
   "source": [
    "to_ignore = ['sim2real_gta5_to_cityscapes']\n",
    "hf_datasets_info = sorted( [datainfo.id for datainfo in hfapi.list_datasets(author=\"Chris1\") \\\n",
    "                           if datainfo.id.split('/')[-1] not in to_ignore] )\n",
    "\n",
    "\n",
    "cnt = 1\n",
    "total = len(hf_datasets_info)* (len(hf_datasets_info) -1)//2\n",
    "for idx1, hf_datapath1 in enumerate(hf_datasets_info):\n",
    "    for idx2 in range(idx1+1, len(hf_datasets_info) )  :\n",
    "        #hf_org = hf_datapath1.split('/')[0]\n",
    "        hf_datapath2 = hf_datasets_info[idx2] \n",
    "        ds_name1 = hf_datapath1.split('/')[-1]\n",
    "        ds_name2 = hf_datapath2.split('/')[-1]\n",
    "        \n",
    "        model_name = f'{ds_name1}__2__{ds_name2}'\n",
    "        \n",
    "        if model_name not in created_models:\n",
    "            print(f'[{cnt }/{total}] - Creating {model_name}')\n",
    "        else:\n",
    "            print(f'[{cnt }/{total}] - Already created {model_name}')\n",
    "        \n",
    "        \n",
    "        hyperparams_cyclegan = { \n",
    "                        'lr':[0.0002], \n",
    "                        'num_epochs':[100], \n",
    "                        'decay_epoch':[80] , #100 \n",
    "                        'n_residual_blocks':[9], \n",
    "                        'lambda_cyc':[10.0], \n",
    "                        'lambda_id':[5.0], \n",
    "                        'beta1':[0.5], 'beta2':[0.999], \n",
    "                        'batch_size':[8], \n",
    "                        'source_dataset_name':[f'Chris1/{ds_name1}'],\n",
    "                        'target_dataset_name':[f'Chris1/{ds_name2}'],\n",
    "                        #'dataset_name':['Chris1/dooggies__2__nftrex'],#['Chris1/NFT_cryptopunks_to_bored_apes_HQ'],#['Chris1/NFT_cryptopunks_to_bored_apes'], \n",
    "                        'channels':[3], \n",
    "                        'checkpoint_interval':[5], #'cpu':[False], \n",
    "                        'epoch':[0], #'fp16':[False], \n",
    "                        'image_size':[256], #256\n",
    "                        'mixed_precision':['no'], \n",
    "                        'num_workers':[8], \n",
    "                        'organization_name':['Chris1'], \n",
    "                        'wandb':[True],\n",
    "                        'push_to_hub':[True], \n",
    "                        'model_name':['cyclegan'],\n",
    "                        #'pytorch_dump_folder_path':[f'torch_dump_{ds_name1}__2__{ds_name2}'], \n",
    "                        'sample_interval':[10] }\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        import copy\n",
    "        import pandas as pd\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        for idx, grid in enumerate(ParameterGrid(hyperparams_cyclegan)):\n",
    "                \n",
    "                EXPERIMENT_NAME = grid['model_name']\n",
    "                copy_grid = copy.deepcopy(grid)\n",
    "                if 'source_dataset_name' in copy_grid:\n",
    "                    del copy_grid['source_dataset_name']\n",
    "                if 'target_dataset_name' in copy_grid:\n",
    "                    del copy_grid['target_dataset_name']\n",
    "                if 'dataset' in copy_grid:\n",
    "                    del copy_grid['dataset']\n",
    "                if 'output_dir' in copy_grid:\n",
    "                    del copy_grid['output_dir']\n",
    "\n",
    "                call_params = ['accelerate', 'launch',\n",
    "                               '--config_file','~/.cache/huggingface/accelerate/default_config.yaml',\n",
    "                               'train.py']\n",
    "\n",
    "           \n",
    "                grid['output_dir'] = 'experiments'\n",
    "\n",
    "                for k,v in grid.items():\n",
    "\n",
    "\n",
    "                    call_params.append(f'--{k}' )\n",
    "                    if k not in  ['cpu', 'wandb','fp16','push_to_hub']:\n",
    "                        call_params.append(f'{v}' )\n",
    "\n",
    "                print(' '.join(call_params))\n",
    "                call(call_params)\n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml train.py --batch_size 8 --beta1 0.5 --beta2 0.999 --channels 3 --checkpoint_interval 5 --decay_epoch 80 --epoch 0 --image_size 256 --lambda_cyc 10.0 --lambda_id 5.0 --lr 0.0002 --mixed_precision no --model_name cyclegan --n_residual_blocks 9 --num_epochs 100 --num_workers 8 --organization_name Chris1 --push_to_hub --sample_interval 10 --source_dataset_name Chris1/azuki --target_dataset_name Chris1/bored-ape-kennel-club --wandb --output_dir experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07817463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d1 = 'boredapeyachtclub'\n",
    "d2 = 'mutant-ape-yacht-club'\n",
    "hyperparams_cyclegan = { \n",
    "                        'lr':[0.0002], \n",
    "                        'num_epochs':[200], \n",
    "                        'decay_epoch':[100] , #100 \n",
    "                        'n_residual_blocks':[9], \n",
    "                        'lambda_cyc':[10.0], \n",
    "                        'lambda_id':[5.0], \n",
    "                        'beta1':[0.5], 'beta2':[0.999], \n",
    "                        'batch_size':[12], \n",
    "                        'source_dataset_name':[f'Chris1/{d1}'],\n",
    "                        'target_dataset_name':[f'Chris1/{d2}'],\n",
    "                        #'dataset_name':['Chris1/dooggies__2__nftrex'],#['Chris1/NFT_cryptopunks_to_bored_apes_HQ'],#['Chris1/NFT_cryptopunks_to_bored_apes'], \n",
    "                        'channels':[3], \n",
    "                        'checkpoint_interval':[5], #'cpu':[False], \n",
    "                        'epoch':[0], #'fp16':[False], \n",
    "                        'image_size':[256], #256\n",
    "                        'mixed_precision':['no'], \n",
    "                        'num_workers':[8], \n",
    "                        'organization_name':['Chris1'], \n",
    "                        'wandb':[True],\n",
    "                        'push_to_hub':[True], \n",
    "                        'model_name':[f'cyclegan_{d1}__2__{d2}'],\n",
    "                        'pytorch_dump_folder_path':[f'torch_dump_{d1}__2__{d2}'], \n",
    "                        'sample_interval':[600] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5661d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "EXPERIMENTS_DATA_CSV = 'experiments.csv'\n",
    "\n",
    "if not os.path.exists(EXPERIMENTS_DATA_CSV):\n",
    "    experiments_df = pd.DataFrame()\n",
    "else:\n",
    "    experiments_df = pd.read_csv(EXPERIMENTS_DATA_CSV)\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = 'cyclegan_toadz__2__minimutants'\n",
    "    \n",
    "\n",
    "for idx, grid in enumerate(ParameterGrid(hyperparams_cyclegan)):\n",
    "\n",
    "        copy_grid = copy.deepcopy(grid)\n",
    "        if 'dataset_name' in copy_grid:\n",
    "            del copy_grid['dataset_name']\n",
    "        if 'dataset' in copy_grid:\n",
    "            del copy_grid['dataset']\n",
    "        if 'output_dir' in copy_grid:\n",
    "            del copy_grid['output_dir']\n",
    "            \n",
    "        experiment_name =  '--'.join([f'{k}__{v}'  for k,v in copy_grid.items() ])\n",
    "        call_params = ['accelerate', 'launch',\n",
    "                       '--config_file','~/.cache/huggingface/accelerate/default_config.yaml',\n",
    "                       'train.py']\n",
    "        \n",
    "        \n",
    "        experiment_id = len(experiments_df)\n",
    "        grid['output_dir'] = experiment_name\n",
    "        \n",
    "        experiments_df = experiments_df.append(grid,ignore_index=True)\n",
    "        grid['output_dir'] = f'experiments/{EXPERIMENT_NAME}/{experiment_id}'\n",
    "        grid['pytorch_dump_folder_path'] = f'experiments/{grid[\"pytorch_dump_folder_path\"]}_{experiment_id}'\n",
    "        grid['model_name'] = f'{grid[\"model_name\"]}_{experiment_id}'\n",
    "        for k,v in grid.items():\n",
    "            \n",
    "             \n",
    "            call_params.append(f'--{k}' )\n",
    "            if k not in  ['cpu', 'wandb','fp16','push_to_hub']:\n",
    "                call_params.append(f'{v}' )\n",
    "                \n",
    "        print(' '.join(call_params))\n",
    "        call(call_params)\n",
    "        \n",
    "        \n",
    "        experiments_df.to_csv(EXPERIMENTS_DATA_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml train.py --batch_size 8 --beta1 0.5 --beta2 0.999 --channels 3 --checkpoint_interval 5 --decay_epoch 100 --epoch 0 --image_size 256 --lambda_cyc 10.0 --lambda_id 5.0 --lr 0.0002 --mixed_precision no --model_name test_cyclegan_toadz__2__minimutants_2 --n_residual_blocks 9 --num_epochs 200 --num_workers 8 --organization_name Chris1 --push_to_hub --pytorch_dump_folder_path experiments/torch_dump_toadz__2__minimutants_2 --sample_interval 30 --source_dataset_name Chris1/cryptopunks_HQ --target_dataset_name Chris1/bored_apes_yacht_club_HQ --wandb --output_dir experiments/cyclegan_toadz__2__minimutants/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549aca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml train.py --batch_size 8 --beta1 0.5 --beta2 0.999 --channels 3 --checkpoint_interval 5 --decay_epoch 100 --epoch 0 --image_size 256 --lambda_cyc 10.0 --lambda_id 5.0 --lr 0.0002 --mixed_precision no --model_name test_cyclegan_toadz__2__minimutants_3 --n_residual_blocks 9 --num_epochs 200 --num_workers 8 --organization_name Chris1 --push_to_hub --pytorch_dump_folder_path experiments/torch_dump_toadz__2__minimutants_3 --sample_interval 30 --source_dataset_name huggingnft/cryptoadz-by-gremplin --target_dataset_name huggingnft/mini-mutants --wandb --output_dir experiments/cyclegan_toadz__2__minimutants/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77bf24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugenv",
   "language": "python",
   "name": "hugenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
