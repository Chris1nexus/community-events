{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install datasets\n",
    "!pip install ipywidgets\n",
    "!pip install pandas\n",
    "!git clone https://github.com/Chris1nexus/community-events.git\n",
    "%cd community-events\n",
    "!pip install .\n",
    "%cd ..\n",
    "!rm -rf community-events\n",
    "!pip install wandb\n",
    "#!huggingface-cli login\n",
    "#!wandb login\n",
    "#!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07817463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from subprocess import call\n",
    "import os\n",
    "\n",
    "\n",
    "'''\n",
    "Reference parameters \n",
    "\n",
    "hyperparams_cyclegan = {\n",
    "    'decay_epoch':[10] , #100\n",
    "    'lr':[0.0002], \n",
    "    'n_residual_blocks':[9], \n",
    "    \n",
    "    'lambda_cyc':[10.0], \n",
    "    'lambda_id':[5.0], \n",
    "    'beta1':[0.5], \n",
    "    'beta2':[0.999], \n",
    "    'batch_size':[8],\n",
    "    \n",
    "    'dataset_name':['Chris1/sim2real_gta5_to_cityscapes'],#['Chris1/NFT_cryptopunks_to_bored_apes'],  \n",
    "\n",
    "    'channels':[3], \n",
    "    'checkpoint_interval':[10], \n",
    "    #'cpu':[False],     \n",
    "    'epoch':[0], \n",
    "    #'fp16':[False], \n",
    "    'image_size':[256], \n",
    "    'mixed_precision':['no'], \n",
    "    'num_epochs':[20], \n",
    "    'num_workers':[8], \n",
    "    'organization_name':['Chris1'], \n",
    "    \n",
    "    'wandb':[True],\n",
    "    'push_to_hub':[True], \n",
    "    'model_name':['test'],\n",
    "    \n",
    "    'pytorch_dump_folder_path':[None], \n",
    "    'sample_interval':[100]\n",
    "                     }\n",
    "\n",
    "hyperparams_cyclegan = { \n",
    "                        'lr':[0.0002], \n",
    "                        'num_epochs':[2], \n",
    "                        'decay_epoch':[1] , #100 \n",
    "                        'n_residual_blocks':[9], \n",
    "                        'lambda_cyc':[10.0], 'lambda_id':[5.0], \n",
    "                        'beta1':[0.5], 'beta2':[0.999], \n",
    "                        'batch_size':[128],#[128], \n",
    "                        'dataset_name':['Chris1/NFT_cryptopunks_to_bored_apes_HQ'],#['Chris1/NFT_cryptopunks_to_bored_apes'], \n",
    "                        'channels':[3], \n",
    "                        'checkpoint_interval':[5], #'cpu':[False], \n",
    "                        'epoch':[0], #'fp16':[False], \n",
    "                        'image_size':[64], #256\n",
    "                        'mixed_precision':['no'], \n",
    "                        'num_workers':[8], \n",
    "                        'organization_name':['Chris1'], \n",
    "                        'wandb':[True],\n",
    "                        'push_to_hub':[True], \n",
    "                        'model_name':['test_cyclegan_punk_to_apes'],\n",
    "                        'pytorch_dump_folder_path':['torch_dump_punk_to_apes'], \n",
    "                        'sample_interval':[30] }\n",
    "'''\n",
    "hyperparams_cyclegan = { \n",
    "                        'lr':[0.0002], \n",
    "                        'num_epochs':[200], \n",
    "                        'decay_epoch':[100] , #100 \n",
    "                        'n_residual_blocks':[9], \n",
    "                        'lambda_cyc':[10.0], \n",
    "                        'lambda_id':[5.0], \n",
    "                        'beta1':[0.5], 'beta2':[0.999], \n",
    "                        'batch_size':[8], \n",
    "                        'source_dataset_name':['huggingnft/cryptoadz-by-gremplin'],\n",
    "                        'target_dataset_name':['huggingnft/mini-mutants'],\n",
    "                        #'dataset_name':['Chris1/dooggies__2__nftrex'],#['Chris1/NFT_cryptopunks_to_bored_apes_HQ'],#['Chris1/NFT_cryptopunks_to_bored_apes'], \n",
    "                        'channels':[3], \n",
    "                        'checkpoint_interval':[5], #'cpu':[False], \n",
    "                        'epoch':[0], #'fp16':[False], \n",
    "                        'image_size':[256], #256\n",
    "                        'mixed_precision':['no'], \n",
    "                        'num_workers':[8], \n",
    "                        'organization_name':['Chris1'], \n",
    "                        'wandb':[True],\n",
    "                        'push_to_hub':[True], \n",
    "                        'model_name':['test_cyclegan_toadz__2__minimutants'],\n",
    "                        'pytorch_dump_folder_path':['torch_dump_toadz__2__minimutants'], \n",
    "                        'sample_interval':[30] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2c5661d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8531/2398649201.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  experiments_df = experiments_df.append(grid,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml train.py --batch_size 8 --beta1 0.5 --beta2 0.999 --channels 3 --checkpoint_interval 5 --decay_epoch 100 --epoch 0 --image_size 256 --lambda_cyc 10.0 --lambda_id 5.0 --lr 0.0002 --mixed_precision no --model_name test_cyclegan_toadz__2__minimutants_3 --n_residual_blocks 9 --num_epochs 200 --num_workers 8 --organization_name Chris1 --push_to_hub --pytorch_dump_folder_path experiments/torch_dump_toadz__2__minimutants_3 --sample_interval 30 --source_dataset_name huggingnft/cryptoadz-by-gremplin --target_dataset_name huggingnft/mini-mutants --wandb --output_dir experiments/cyclegan_toadz__2__minimutants/3\n",
      "Namespace(batch_size=8, beta1=0.5, beta2=0.999, channels=3, checkpoint_interval=5, cpu=False, decay_epoch=100, epoch=0, fp16=False, image_size=256, lambda_cyc=10.0, lambda_id=5.0, lr=0.0002, mixed_precision='no', model_name='test_cyclegan_toadz__2__minimutants_3', n_residual_blocks=9, num_epochs=200, num_workers=8, organization_name='Chris1', output_dir=PosixPath('experiments/cyclegan_toadz__2__minimutants/3'), push_to_hub=True, pytorch_dump_folder_path=PosixPath('experiments/torch_dump_toadz__2__minimutants_3'), sample_interval=30, source_dataset_name='huggingnft/cryptoadz-by-gremplin', target_dataset_name='huggingnft/mini-mutants', wandb=True)\n",
      "Namespace(batch_size=8, beta1=0.5, beta2=0.999, channels=3, checkpoint_interval=5, cpu=False, decay_epoch=100, epoch=0, fp16=False, image_size=256, lambda_cyc=10.0, lambda_id=5.0, lr=0.0002, mixed_precision='no', model_name='test_cyclegan_toadz__2__minimutants_3', n_residual_blocks=9, num_epochs=200, num_workers=8, organization_name='Chris1', output_dir=PosixPath('experiments/cyclegan_toadz__2__minimutants/3'), push_to_hub=True, pytorch_dump_folder_path=PosixPath('experiments/torch_dump_toadz__2__minimutants_3'), sample_interval=30, source_dataset_name='huggingnft/cryptoadz-by-gremplin', target_dataset_name='huggingnft/mini-mutants', wandb=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         call_params\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(call_params))\n\u001b[0;32m---> 45\u001b[0m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m experiments_df\u001b[38;5;241m.\u001b[39mto_csv(EXPERIMENTS_DATA_CSV)\n",
      "File \u001b[0;32m/usr/lib/python3.8/subprocess.py:342\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         p\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.8/subprocess.py:1083\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/subprocess.py:1806\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1806\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1809\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.8/subprocess.py:1764\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1764\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "EXPERIMENTS_DATA_CSV = 'experiments.csv'\n",
    "\n",
    "if not os.path.exists(EXPERIMENTS_DATA_CSV):\n",
    "    experiments_df = pd.DataFrame()\n",
    "else:\n",
    "    experiments_df = pd.read_csv(EXPERIMENTS_DATA_CSV)\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = 'cyclegan_toadz__2__minimutants'\n",
    "    \n",
    "\n",
    "for idx, grid in enumerate(ParameterGrid(hyperparams_cyclegan)):\n",
    "\n",
    "        copy_grid = copy.deepcopy(grid)\n",
    "        if 'dataset_name' in copy_grid:\n",
    "            del copy_grid['dataset_name']\n",
    "        if 'dataset' in copy_grid:\n",
    "            del copy_grid['dataset']\n",
    "        if 'output_dir' in copy_grid:\n",
    "            del copy_grid['output_dir']\n",
    "            \n",
    "        experiment_name =  '--'.join([f'{k}__{v}'  for k,v in copy_grid.items() ])\n",
    "        call_params = ['accelerate', 'launch',\n",
    "                       '--config_file','~/.cache/huggingface/accelerate/default_config.yaml',\n",
    "                       'train.py']\n",
    "        \n",
    "        \n",
    "        experiment_id = len(experiments_df)\n",
    "        grid['output_dir'] = experiment_name\n",
    "        \n",
    "        experiments_df = experiments_df.append(grid,ignore_index=True)\n",
    "        grid['output_dir'] = f'experiments/{EXPERIMENT_NAME}/{experiment_id}'\n",
    "        grid['pytorch_dump_folder_path'] = f'experiments/{grid[\"pytorch_dump_folder_path\"]}_{experiment_id}'\n",
    "        grid['model_name'] = f'{grid[\"model_name\"]}_{experiment_id}'\n",
    "        for k,v in grid.items():\n",
    "            \n",
    "             \n",
    "            call_params.append(f'--{k}' )\n",
    "            if k not in  ['cpu', 'wandb','fp16','push_to_hub']:\n",
    "                call_params.append(f'{v}' )\n",
    "                \n",
    "        print(' '.join(call_params))\n",
    "        call(call_params)\n",
    "        \n",
    "        \n",
    "        experiments_df.to_csv(EXPERIMENTS_DATA_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31069e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Namespace(batch_size=8, beta1=0.5, beta2=0.999, channels=3, checkpoint_interval=5, cpu=False, decay_epoch=100, epoch=0, fp16=False, image_size=256, lambda_cyc=10.0, lambda_id=5.0, lr=0.0002, mixed_precision='no', model_name='test_cyclegan_toadz__2__minimutants_2', n_residual_blocks=9, num_epochs=200, num_workers=8, organization_name='Chris1', output_dir=PosixPath('experiments/cyclegan_toadz__2__minimutants/2'), push_to_hub=True, pytorch_dump_folder_path=PosixPath('experiments/torch_dump_toadz__2__minimutants_2'), sample_interval=30, source_dataset_name='Chris1/cryptopunks_HQ', target_dataset_name='Chris1/bored_apes_yacht_club_HQ', wandb=True)\n",
      "Namespace(batch_size=8, beta1=0.5, beta2=0.999, channels=3, checkpoint_interval=5, cpu=False, decay_epoch=100, epoch=0, fp16=False, image_size=256, lambda_cyc=10.0, lambda_id=5.0, lr=0.0002, mixed_precision='no', model_name='test_cyclegan_toadz__2__minimutants_2', n_residual_blocks=9, num_epochs=200, num_workers=8, organization_name='Chris1', output_dir=PosixPath('experiments/cyclegan_toadz__2__minimutants/2'), push_to_hub=True, pytorch_dump_folder_path=PosixPath('experiments/torch_dump_toadz__2__minimutants_2'), sample_interval=30, source_dataset_name='Chris1/cryptopunks_HQ', target_dataset_name='Chris1/bored_apes_yacht_club_HQ', wandb=True)\n",
      "/home/xrh1/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchris1nexus\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "Using custom data configuration Chris1--cryptopunks_HQ-cf2ec687559f7bbd\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/Chris1--cryptopunks_HQ-cf2ec687559f7bbd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 910.82it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/xrh1/experiments/huggan/huggan_repo/community-events/huggan/pytorch/cyclegan/wandb/run-20220414_180121-3ek5tucc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33methereal-capybara-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chris1nexus/experiments--cyclegan_toadz__2__minimutants--2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chris1nexus/experiments--cyclegan_toadz__2__minimutants--2/runs/3ek5tucc\u001b[0m\n",
      "/home/xrh1/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Using custom data configuration Chris1--bored_apes_yacht_club_HQ-3040cd75656f98b3\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/Chris1--bored_apes_yacht_club_HQ-3040cd75656f98b3/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1009.22it/s]\n",
      "Using custom data configuration Chris1--cryptopunks_HQ-cf2ec687559f7bbd\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/Chris1--cryptopunks_HQ-cf2ec687559f7bbd/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 783.10it/s]\n",
      "Using custom data configuration Chris1--bored_apes_yacht_club_HQ-3040cd75656f98b3\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/Chris1--bored_apes_yacht_club_HQ-3040cd75656f98b3/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1579.78it/s]\n",
      "Starting training\n",
      "Starting training\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 473, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 469, in main\n",
      "    training_function({}, args)\n",
      "  File \"train.py\", line 286, in training_function\n",
      "    accelerator.backward(loss_G)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/accelerate/accelerator.py\", line 470, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 23.69 GiB total capacity; 18.55 GiB already allocated; 158.75 MiB free; 19.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 473, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 469, in main\n",
      "    training_function({}, args)\n",
      "  File \"train.py\", line 286, in training_function\n",
      "    accelerator.backward(loss_G)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/accelerate/accelerator.py\", line 470, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 23.69 GiB total capacity; 18.55 GiB already allocated; 158.75 MiB free; 19.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33methereal-capybara-8\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/chris1nexus/experiments--cyclegan_toadz__2__minimutants--2/runs/3ek5tucc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220414_180121-3ek5tucc/logs\u001b[0m\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1587933 closing signal SIGTERM\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1587932) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/launch.py\", line 193, in <module>\n",
      "    main()\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/launch.py\", line 189, in main\n",
      "    launch(args)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/launch.py\", line 174, in launch\n",
      "    run(args)\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/run.py\", line 710, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 259, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2022-04-14_18:01:39\n",
      "  host      : xrh1\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 1587932)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/xrh1/.local/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 468, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/home/xrh1/.local/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 228, in multi_gpu_launcher\r\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'torch.distributed.launch', '--use_env', '--nproc_per_node', '2', 'train.py', '--batch_size', '8', '--beta1', '0.5', '--beta2', '0.999', '--channels', '3', '--checkpoint_interval', '5', '--decay_epoch', '100', '--epoch', '0', '--image_size', '256', '--lambda_cyc', '10.0', '--lambda_id', '5.0', '--lr', '0.0002', '--mixed_precision', 'no', '--model_name', 'test_cyclegan_toadz__2__minimutants_2', '--n_residual_blocks', '9', '--num_epochs', '200', '--num_workers', '8', '--organization_name', 'Chris1', '--push_to_hub', '--pytorch_dump_folder_path', 'experiments/torch_dump_toadz__2__minimutants_2', '--sample_interval', '30', '--source_dataset_name', 'Chris1/cryptopunks_HQ', '--target_dataset_name', 'Chris1/bored_apes_yacht_club_HQ', '--wandb', '--output_dir', 'experiments/cyclegan_toadz__2__minimutants/2']' returned non-zero exit status 1.\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml train.py --batch_size 8 --beta1 0.5 --beta2 0.999 --channels 3 --checkpoint_interval 5 --decay_epoch 100 --epoch 0 --image_size 256 --lambda_cyc 10.0 --lambda_id 5.0 --lr 0.0002 --mixed_precision no --model_name test_cyclegan_toadz__2__minimutants_2 --n_residual_blocks 9 --num_epochs 200 --num_workers 8 --organization_name Chris1 --push_to_hub --pytorch_dump_folder_path experiments/torch_dump_toadz__2__minimutants_2 --sample_interval 30 --source_dataset_name Chris1/cryptopunks_HQ --target_dataset_name Chris1/bored_apes_yacht_club_HQ --wandb --output_dir experiments/cyclegan_toadz__2__minimutants/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xrh1/.local/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Namespace(batch_size=8, beta1=0.5, beta2=0.999, channels=3, checkpoint_interval=5, cpu=False, decay_epoch=100, epoch=0, fp16=False, image_size=256, lambda_cyc=10.0, lambda_id=5.0, lr=0.0002, mixed_precision='no', model_name='test_cyclegan_toadz__2__minimutants_3', n_residual_blocks=9, num_epochs=200, num_workers=8, organization_name='Chris1', output_dir=PosixPath('experiments/cyclegan_toadz__2__minimutants/3'), push_to_hub=True, pytorch_dump_folder_path=PosixPath('experiments/torch_dump_toadz__2__minimutants_3'), sample_interval=30, source_dataset_name='huggingnft/cryptoadz-by-gremplin', target_dataset_name='huggingnft/mini-mutants', wandb=True)\n",
      "Namespace(batch_size=8, beta1=0.5, beta2=0.999, channels=3, checkpoint_interval=5, cpu=False, decay_epoch=100, epoch=0, fp16=False, image_size=256, lambda_cyc=10.0, lambda_id=5.0, lr=0.0002, mixed_precision='no', model_name='test_cyclegan_toadz__2__minimutants_3', n_residual_blocks=9, num_epochs=200, num_workers=8, organization_name='Chris1', output_dir=PosixPath('experiments/cyclegan_toadz__2__minimutants/3'), push_to_hub=True, pytorch_dump_folder_path=PosixPath('experiments/torch_dump_toadz__2__minimutants_3'), sample_interval=30, source_dataset_name='huggingnft/cryptoadz-by-gremplin', target_dataset_name='huggingnft/mini-mutants', wandb=True)\n",
      "/home/xrh1/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchris1nexus\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "Using custom data configuration huggingnft--cryptoadz-by-gremplin-e6207bfef6d4824b\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/huggingnft--cryptoadz-by-gremplin-e6207bfef6d4824b/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/xrh1/experiments/huggan/huggan_repo/community-events/huggan/pytorch/cyclegan/wandb/run-20220414_183213-3eug5ql2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgraceful-puddle-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chris1nexus/experiments--cyclegan_toadz__2__minimutants--3\u001b[0m\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 947.44it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chris1nexus/experiments--cyclegan_toadz__2__minimutants--3/runs/3eug5ql2\u001b[0m\n",
      "/home/xrh1/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Using custom data configuration huggingnft--mini-mutants-af5e655e4dc298e4\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/huggingnft--mini-mutants-af5e655e4dc298e4/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1592.98it/s]\n",
      "Using custom data configuration huggingnft--cryptoadz-by-gremplin-e6207bfef6d4824b\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/huggingnft--cryptoadz-by-gremplin-e6207bfef6d4824b/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 680.01it/s]\n",
      "Using custom data configuration huggingnft--mini-mutants-af5e655e4dc298e4\n",
      "Reusing dataset parquet (/home/xrh1/.cache/huggingface/datasets/parquet/huggingnft--mini-mutants-af5e655e4dc298e4/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 901.23it/s]\n",
      "Starting training\n",
      "Starting training\n",
      "[Epoch 0/200] [Batch 287/395] [D loss: 0.165659] [G loss: 2.432487, adv: 0.530526, cycle: 0.135132, identity: 0.110128] ETA: 22:57:00.5713512996693"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml train.py --batch_size 8 --beta1 0.5 --beta2 0.999 --channels 3 --checkpoint_interval 5 --decay_epoch 100 --epoch 0 --image_size 256 --lambda_cyc 10.0 --lambda_id 5.0 --lr 0.0002 --mixed_precision no --model_name test_cyclegan_toadz__2__minimutants_3 --n_residual_blocks 9 --num_epochs 200 --num_workers 8 --organization_name Chris1 --push_to_hub --pytorch_dump_folder_path experiments/torch_dump_toadz__2__minimutants_3 --sample_interval 30 --source_dataset_name huggingnft/cryptoadz-by-gremplin --target_dataset_name huggingnft/mini-mutants --wandb --output_dir experiments/cyclegan_toadz__2__minimutants/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dd6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugenv",
   "language": "python",
   "name": "hugenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
